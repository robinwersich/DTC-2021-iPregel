---
title: "higgs-twitter Node Importance Measure Analysis"
output: html_notebook
---

## SetUp
```{r}
library(ggplot2)
library(gridExtra)
graph.color <- "#6fa8dc"
border.color <- "grey30"
```


## 0. Dataset description

The provided Twitter network contained an edge from A to B if user A answered or retweeted a tweet by B or if A mentioned B in a tweet. Each edge was labeled with a timestamp and the concrete interaction type. We removed both in order to treat each interaction equally. In addition, the resulting duplicates, as well as self-references, were removed. To obtain the follower count for each user, we used the follower graph provided by SNAP, which contained all users involved in the above-described interactions and calculated the in-degree.

## 1. Load Node Importance Measure and Meta Data

```{r}
pr = read.csv("../results/networkit_pagerank_higgs-activity_time.txt", sep="\t", header = FALSE)
colnames(pr) <- c("ID", "PageRank")
min.pr <- min(pr$PageRank)
#pr <- pr[pr$PageRank != min.pr, ], as first three quartiles of values equal the minimum value it can make sense to exclude them to obtain interpretable distribution plots

bc = read.csv("../results/networkit_betweenness_centrality_higgs-activity_time_reversed.txt", sep="\t", header = FALSE)
colnames(bc) <- c("ID", "BetweennessCentrality")
min.bc <- min(bc$BetweennessCentrality)
#bc <- bc[bc$BetweennessCentrality != min.bc, ], as first three quartiles of values equal the minimum value it can make sense to exclude them to obtain interpretable distribution plots

cc = read.csv("../results/networkit_closeness_centrality_higgs-activity_time_reversed.txt", sep="\t", header = FALSE)
colnames(cc) <- c("ID", "ClosenessCentrality")
min.cc <- min(cc$ClosenessCentrality)
#cc <- cc[cc$ClosenessCentrality != min.cc, ], as first three quartiles of values equal the minimum value it can make sense to exclude them to obtain interpretable distribution plots

# transform ids to be 1-indexed to be able to work easily with them in R
bc$ID <- bc$ID + 1
cc$ID <- cc$ID + 1
pr$ID <- pr$ID + 1

new_measures <- list("PageRank"=pr,"BetweennessCentrality"=bc,"ClosenessCentrality"=cc)

follower_count = read.csv("../results/follower_count_higgs-social_network.txt", sep=" ", header=FALSE)
colnames(follower_count) <- c("ID", "FollowerCount")
# delete rows of twitter users that did not appear in interaction network
follower_count <- follower_count[follower_count$ID %in% bc$ID,]
```

## 2. Feasibility of PageRank, Betweenness Centrality and Closeness Centrality as Node Importance Measures

To evaluate feasibility, we assess whether each node got assigned a meaningful score and if the resulting distribution of scores serves well for distinguishing nodes. We do this via visual inspection of the histograms of the resulting distributions per measure. As some measures have a huge spread of values (e.g. Betweenness Centrality) we plot a histogram with outliers, a histogram of only the interquartile range and additionally histograms of the outlier distribution and inspect all of them.

### Histograms including outliers

```{r}
bins <- list(PageRank=100, BetweennessCentrality=100, ClosenessCentrality=100)

for (measure in names(new_measures)) {
  p <- ggplot(new_measures[[measure]]) + aes_string(x=measure) + geom_histogram(bins=bins[[measure]], fill=graph.color, color=border.color) + labs(title=paste(measure, "Distribution"), y="Count")
  print(p)
}

 p <- ggplot(new_measures[["PageRank"]]) + aes_string(x="PageRank") + geom_histogram(bins=bins[["PageRank"]], fill=graph.color, color=border.color) + labs(title=paste("PageRank", "Distribution"), y="Count")
  print(p)
hist(pr$PageRank)
```

#### Debugging occurrences

```{r}
pagerank.occr <- table(unlist(new_measures[["PageRank"]][["PageRank"]]))
betweenness.centrality.occr <- table(unlist(new_measures[["BetweennessCentrality"]][["BetweennessCentrality"]]))
closeness.centrality.occr <- table(unlist(new_measures[["ClosenessCentrality"]][["ClosenessCentrality"]]))
```

```{r}
summary(new_measures[["PageRank"]])
summary(new_measures[["BetweennessCentrality"]])
summary(new_measures[["ClosenessCentrality"]])
```

## Print Outlier Distributions

```{r}
library(ggplot2)
outliers <- list()
bins <- list(PR=40, BC=40, CC=40)

for (measure in names(new_measures)) {
  cur.measure.stats <- boxplot.stats(new_measures[[measure]][[measure]])
  cur.measure.median <- cur.measure.stats$stats[3]
  cur.measure.outliers <- cur.measure.stats$out
  
  outliers[[measure]] <- list()
  outliers[[measure]][["total"]] <- cur.measure.outliers
  outliers[[measure]][["upper"]] <- cur.measure.outliers[cur.measure.outliers > cur.measure.median]
  outliers[[measure]][["lower"]] <- cur.measure.outliers[cur.measure.outliers < cur.measure.median]
}

for (measure in names(outliers)) {
  p <- ggplot() + aes_string(outliers[[measure]][["upper"]]) + geom_histogram(bins=bins[[measure]], fill=graph.color, color=border.color) + labs(title=paste(measure,"Interquartile Range Upper Outlier Distribution"), x=measure, y="Count")
  print(p)
  p <- ggplot() + aes_string(outliers[[measure]][["lower"]]) + geom_histogram(bins=bins[[measure]], fill=graph.color, color=border.color) + labs(title=paste(measure, "Interquartile Range Lower Outlier Distribution"), x=measure, y="Count")
  print(p)
}
```

## Print Interquartile Range Distribution
```{r}
for (measure in names(outliers)) {
  cur.measure <- new_measures[[measure]]
  cur.outliers <- outliers[[measure]][["total"]]
  p <- ggplot(cur.measure[!(cur.measure[[measure]] %in%  cur.outliers),]) + aes_string(x=measure) + geom_histogram(bins=bins[[measure]], fill=graph.color, color=border.color)
  p <- p + labs(title=paste(measure, "Interquartile Range Distribution"), x=measure, y="Count")
 print(p)
}
```

## 3. Relationship between the obtained classical node importance measure and the newly calculated node importance measures

### 3.1 Distribution of classical node importance measure
```{r}
p <- ggplot(follower_count, aes_string(x="FollowerCount")) + geom_histogram(bins=40, fill=graph.color, color=border.color) + labs(title="Follower Count Distribution", y="Count")
print(p)
```
```{r}
classical.measure.stats <- boxplot.stats(follower_count$FollowerCount)
classical.measure.median <- classical.measure.stats$stats[3]
classical.measure.outliers <- classical.measure.stats$out

outliers.classical.measure <- list()
outliers.classical.measure[["total"]] <- classical.measure.outliers
outliers.classical.measure[["upper"]] <- classical.measure.outliers[classical.measure.outliers > classical.measure.median]
outliers.classical.measure[["lower"]] <- classical.measure.outliers[classical.measure.outliers < classical.measure.median]
 
p <- ggplot(follower_count[!(follower_count[["FollowerCount"]] %in% outliers.classical.measure[["total"]]),]) + aes_string(x="FollowerCount") + geom_histogram(bins=40, fill=graph.color, color=border.color)
p <- p + labs(title="Follower Count Interquartile Range Distribution", x="Follower Count", y="Count")
print(p)
```

### 3.2 Relationship of new network-based measures with classical node importance measure
```{r relationship between h-index and new measures, fig.height = 2, fig.width = 12}

plots <- list()
for (measure in names(new_measures)) {
  data.combined <- cbind(new_measures[[measure]], follower_count)
  data.combined <- data.combined[2:4] #drop duplicate ID column
  p <- ggplot(data.combined) + aes_string(x=measure, y="FollowerCount") + geom_point(alpha = 0.65, color=graph.color) + labs(title= paste(measure, "vs. Follower Count"), x=measure, y="Follower Count")
  plots[[measure]] <- p
}

grid.arrange(grobs = plots, ncol=3)

```

3a. Pearson Correlation
```{r}
pearson.correlation <- list()
for (measure in names(new_measures)){
  cur.cor.r <- cor(new_measures[[measure]][[measure]], follower_count$FollowerCount)
  cur.cor.r2 <- cur.cor.r ^ 2
  pearson.correlation[[measure]][["r"]] <- cur.cor.r
  pearson.correlation[[measure]][["r2"]] <- cur.cor.r2
}

```

3b. Spearman Correlation

```{r}
spearman.correlation <- list()
for (measure in names(new_measures)){
  cur.s.cor.r <- cor(new_measures[[measure]][[measure]], follower_count$FollowerCount, method="spearman")
  cur.s.cor.r2 <- cur.s.cor.r ^ 2
  spearman.correlation[[measure]][["r"]] <- cur.s.cor.r
  spearman.correlation[[measure]][["r2"]] <- cur.s.cor.r2
}
```

## 4. Network properties

We investigated the number of people that interacted only once, with only one outgoing edge, to find out what causes the huge amount of nodes being assigned the minimum value for each measure.

```{r}
network = read.csv("../data_prepared/prepared_higgs-activity_time.txt", sep=" ", header = FALSE)
colnames(network) <- c("Source", "Target")
source.with.one.outgoing_edge <- which(!(duplicated(network$Source)|duplicated(network$Source, fromLast=TRUE)))
# make sure source nodes are not target nodes
source.with.one.outgoing_edge <- source.with.one.outgoing_edge[! source.with.one.outgoing_edge %in% network$Target]
```



